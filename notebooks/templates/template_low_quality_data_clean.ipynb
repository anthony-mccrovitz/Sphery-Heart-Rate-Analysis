{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Low Quality Heart Rate Data Processing Template\n",
        "\n",
        "**Purpose:** Process heart rate data with poor sensor connection, noise, or missing segments.\n",
        "\n",
        "**Data Quality Issues Simulated:**\n",
        "- Sparse data points (sensor disconnections)\n",
        "- Irregular recording intervals\n",
        "- Missing or distorted peaks\n",
        "- Noisy baseline readings\n",
        "\n",
        "**Workflow:**\n",
        "1. Setup and data loading\n",
        "2. Data quality assessment\n",
        "3. Simple visualization (documentation only)\n",
        "4. Export session-level CSV (no station boundaries)\n",
        "\n",
        "**Expected Outcome:** Session-level record with data quality documentation for research transparency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# STEP 1: Setup and Configuration\n",
        "# ‚ö†Ô∏è CHANGE USER_ID FOR EACH LOW-QUALITY USER\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import display\n",
        "import csv\n",
        "\n",
        "# Set working directory\n",
        "os.chdir('/Users/anthonymccrovitz/Desktop/Sphery/Sphere Heart Rate Analysis')\n",
        "sys.path.append('scripts')\n",
        "\n",
        "# Import TCX parser\n",
        "from parse_tcx import parse_tcx_to_df\n",
        "\n",
        "# ‚ö†Ô∏è CONFIGURATION - CHANGE FOR EACH USER\n",
        "USER_ID = 99  # ‚Üê CHANGE THIS TO THE ACTUAL USER NUMBER\n",
        "TCX_FILE = f'data/{USER_ID}-d.tcx'\n",
        "OUTPUT_CSV = f'output/processed/user_{USER_ID}_station_data_low_quality.csv'\n",
        "\n",
        "print(f\"üö® LOW QUALITY DATA PROCESSING for User {USER_ID}\")\n",
        "print(f\"üìÅ TCX file: {TCX_FILE}\")\n",
        "print(f\"üíæ Output CSV: {OUTPUT_CSV}\")\n",
        "print(\"‚úÖ Libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# STEP 2: Load and Parse TCX Data\n",
        "# Handle potential parsing errors gracefully\n",
        "\n",
        "try:\n",
        "    result = parse_tcx_to_df(TCX_FILE)\n",
        "    if len(result) == 4:\n",
        "        df, session_total_sec, session_avg_hr, session_max_hr = result\n",
        "        calories_burned = None\n",
        "    else:\n",
        "        df, session_total_sec, session_avg_hr, session_max_hr, calories_burned = result\n",
        "    \n",
        "    session_duration_min = session_total_sec / 60\n",
        "    \n",
        "    print(f\"‚úÖ Successfully parsed TCX file\")\n",
        "    print(f\"üìä Raw Data Summary:\")\n",
        "    print(f\"   Duration: {session_duration_min:.2f} minutes\")\n",
        "    print(f\"   Data points: {len(df)}\")\n",
        "    print(f\"   Average HR: {session_avg_hr:.1f} bpm\")\n",
        "    print(f\"   Maximum HR: {session_max_hr} bpm\")\n",
        "    if calories_burned:\n",
        "        print(f\"   Calories: {calories_burned}\")\n",
        "    \n",
        "    # Display first few rows\n",
        "    print(f\"\\nüìã Data Preview:\")\n",
        "    display(df.head())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error parsing TCX file: {e}\")\n",
        "    print(\"Please check that the TCX file exists and is valid.\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# STEP 3: Data Quality Assessment\n",
        "# Analyze data density and identify quality issues\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER {USER_ID} DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate data density\n",
        "data_points_per_minute = len(df) / session_duration_min\n",
        "expected_points_per_minute = 12  # Typical Garmin recording rate\n",
        "\n",
        "# Assess data quality based on density\n",
        "if data_points_per_minute < 3:\n",
        "    quality_level = \"VERY LOW\"\n",
        "    quality_reason = \"Severe sensor disconnection - extremely sparse data\"\n",
        "elif data_points_per_minute < 6:\n",
        "    quality_level = \"LOW\"\n",
        "    quality_reason = \"Frequent sensor disconnections - insufficient data density\"\n",
        "elif data_points_per_minute < 10:\n",
        "    quality_level = \"MARGINAL\"\n",
        "    quality_reason = \"Intermittent sensor issues - below normal recording rate\"\n",
        "else:\n",
        "    quality_level = \"ACCEPTABLE\"\n",
        "    quality_reason = \"Data density acceptable but may have other quality issues\"\n",
        "\n",
        "print(f\"\\nüö® DATA QUALITY: {quality_level}\")\n",
        "print(f\"\\nüìä Quality Metrics:\")\n",
        "print(f\"   Data density: {data_points_per_minute:.1f} points/minute\")\n",
        "print(f\"   Expected density: ~{expected_points_per_minute} points/minute\")\n",
        "print(f\"   Coverage: {(data_points_per_minute/expected_points_per_minute)*100:.1f}% of expected\")\n",
        "print(f\"   Assessment: {quality_reason}\")\n",
        "\n",
        "# Additional quality checks\n",
        "hr_range = df['heart_rate'].max() - df['heart_rate'].min()\n",
        "hr_std = df['heart_rate'].std()\n",
        "time_gaps = df['elapsed_min'].diff().describe()\n",
        "\n",
        "print(f\"\\nüìà Heart Rate Characteristics:\")\n",
        "print(f\"   Range: {hr_range} bpm (min: {df['heart_rate'].min()}, max: {df['heart_rate'].max()})\")\n",
        "print(f\"   Standard deviation: {hr_std:.1f} bpm\")\n",
        "print(f\"   Mean recording interval: {time_gaps['mean']:.2f} minutes\")\n",
        "print(f\"   Max gap between readings: {time_gaps['max']:.2f} minutes\")\n",
        "\n",
        "# Store quality assessment for CSV export\n",
        "quality_summary = f\"{quality_level} QUALITY DATA: Data density {data_points_per_minute:.1f} points/minute ({(data_points_per_minute/expected_points_per_minute)*100:.1f}% of expected). {quality_reason}. Heart rate range {hr_range} bpm with {hr_std:.1f} bpm standard deviation. Maximum recording gap {time_gaps['max']:.2f} minutes indicates sensor connection issues.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# STEP 4: Load User Metadata (if available)\n",
        "# Attempt to load demographic and session information\n",
        "\n",
        "try:\n",
        "    metadata_df = pd.read_csv('metadata/user_metadata.csv')\n",
        "    user_meta = metadata_df[metadata_df['user_id'] == USER_ID]\n",
        "    \n",
        "    if not user_meta.empty:\n",
        "        user_meta = user_meta.iloc[0]\n",
        "        age = user_meta['age'] if not pd.isna(user_meta['age']) else None\n",
        "        gender = user_meta['gender'] if not pd.isna(user_meta['gender']) else None\n",
        "        height_cm = user_meta['height_cm'] if not pd.isna(user_meta['height_cm']) else None\n",
        "        weight_kg = user_meta['weight_kg'] if not pd.isna(user_meta['weight_kg']) else None\n",
        "        champ_number = user_meta['champ_number'] if not pd.isna(user_meta['champ_number']) else None\n",
        "        print(f\"‚úÖ Loaded metadata for user {USER_ID}:\")\n",
        "        print(f\"   Age: {age}, Gender: {gender}\")\n",
        "        print(f\"   Height: {height_cm}cm, Weight: {weight_kg}kg\")\n",
        "        print(f\"   Champion number: {champ_number}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è No metadata found for user {USER_ID}\")\n",
        "        age = gender = height_cm = weight_kg = champ_number = None\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error loading metadata: {e}\")\n",
        "    age = gender = height_cm = weight_kg = champ_number = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# STEP 5: Create Documentation Plot\n",
        "# Simple heart rate over time plot for research documentation\n",
        "\n",
        "# Create output directory\n",
        "plots_dir = f'output/plots/user_{USER_ID}'\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "# Create documentation plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot raw heart rate data\n",
        "plt.plot(df['elapsed_min'], df['heart_rate'], \n",
        "         marker='o', markersize=3, linewidth=1.5, \n",
        "         color='red', alpha=0.7, label='Heart Rate Data')\n",
        "\n",
        "# Add quality indicator\n",
        "plt.axhline(y=df['heart_rate'].mean(), color='blue', linestyle='--', \n",
        "           alpha=0.5, label=f'Session Average ({df[\"heart_rate\"].mean():.1f} bpm)')\n",
        "\n",
        "# Formatting\n",
        "plt.xlabel('Elapsed Minutes', fontsize=12)\n",
        "plt.ylabel('Heart Rate (BPM)', fontsize=12)\n",
        "plt.title(f'User {USER_ID} - Heart Rate Over Time ({quality_level} Quality Data)', fontsize=14)\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Add quality annotation\n",
        "plt.text(0.02, 0.98, f'{quality_level} QUALITY DATA\\nNo station boundaries determined', \n",
        "         transform=plt.gca().transAxes, fontsize=10, verticalalignment='top',\n",
        "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plot_path = f'{plots_dir}/heart_rate_over_time_low_quality.png'\n",
        "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úÖ Documentation plot saved to: {plot_path}\")\n",
        "print(f\"üìä Data points plotted: {len(df)}\")\n",
        "print(f\"‚ö†Ô∏è No station-based analysis performed due to data quality issues\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# STEP 6: Export Session-Level CSV\n",
        "# Create single session record in standard format for research database\n",
        "\n",
        "print(\"üì§ EXPORTING SESSION-LEVEL DATA\")\n",
        "print(\"‚ö†Ô∏è Station-level analysis not possible due to data quality issues\")\n",
        "\n",
        "# Calculate session-level statistics\n",
        "session_start_timestamp = df.iloc[0]['timestamp']\n",
        "session_end_timestamp = df.iloc[-1]['timestamp']\n",
        "session_min_hr = df['heart_rate'].min()\n",
        "session_max_hr_calc = df['heart_rate'].max()\n",
        "session_avg_hr_calc = df['heart_rate'].mean()\n",
        "\n",
        "# Use calculated values or TCX parsing results\n",
        "final_session_avg_hr = session_avg_hr if 'session_avg_hr' in locals() else session_avg_hr_calc\n",
        "final_session_max_hr = session_max_hr if 'session_max_hr' in locals() else session_max_hr_calc\n",
        "\n",
        "# Get reference header from high-quality user CSV\n",
        "reference_files = [\n",
        "    'output/processed/user_2_station_data_peaks.csv',\n",
        "    'output/processed/user_4_station_data.csv',\n",
        "    'output/processed/user_11_station_data_peaks.csv'\n",
        "]\n",
        "\n",
        "fieldnames = None\n",
        "reference_used = None\n",
        "\n",
        "for reference_file in reference_files:\n",
        "    try:\n",
        "        with open(reference_file, 'r') as ref:\n",
        "            reference_reader = csv.reader(ref)\n",
        "            fieldnames = next(reference_reader)\n",
        "        reference_used = reference_file\n",
        "        print(f\"‚úÖ Using header structure from {reference_file}\")\n",
        "        break\n",
        "    except FileNotFoundError:\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error reading {reference_file}: {e}\")\n",
        "        continue\n",
        "\n",
        "if fieldnames is None:\n",
        "    print(\"‚ùå No reference CSV found. Please ensure at least one high-quality user CSV exists.\")\n",
        "    raise FileNotFoundError(\"Reference CSV file not found for header structure\")\n",
        "\n",
        "# Create session-level row\n",
        "session_row = {}\n",
        "\n",
        "# Initialize all fields with appropriate defaults\n",
        "for field in fieldnames:\n",
        "    if field in ['user_id']:\n",
        "        session_row[field] = USER_ID\n",
        "    elif field in ['session_start_time']:\n",
        "        session_row[field] = session_start_timestamp.isoformat()\n",
        "    elif field in ['session_end_time']:\n",
        "        session_row[field] = session_end_timestamp.isoformat()\n",
        "    elif field in ['session_duration_min']:\n",
        "        session_row[field] = round(session_duration_min, 2)\n",
        "    elif field in ['session_avg_hr']:\n",
        "        session_row[field] = round(final_session_avg_hr, 2)\n",
        "    elif field in ['session_max_hr']:\n",
        "        session_row[field] = int(final_session_max_hr)\n",
        "    elif field in ['calories_burned']:\n",
        "        session_row[field] = calories_burned if calories_burned else ''\n",
        "    elif field in ['champ_number']:\n",
        "        session_row[field] = champ_number if champ_number else ''\n",
        "    elif field in ['gender']:\n",
        "        session_row[field] = gender if gender else 'TBD'\n",
        "    elif field in ['age']:\n",
        "        session_row[field] = age if age else 'TBD'\n",
        "    elif field in ['height_cm']:\n",
        "        session_row[field] = height_cm if height_cm else ''\n",
        "    elif field in ['weight_kg']:\n",
        "        session_row[field] = weight_kg if weight_kg else ''\n",
        "    elif 'station' in field.lower():\n",
        "        # Station-level fields marked as not available\n",
        "        if 'number' in field.lower():\n",
        "            session_row[field] = 'N/A - LOW QUALITY DATA'\n",
        "        else:\n",
        "            session_row[field] = 'N/A - LOW QUALITY DATA'\n",
        "    elif field in ['data_quality']:\n",
        "        session_row[field] = quality_summary\n",
        "    elif field in ['notes']:\n",
        "        session_row[field] = f'RESEARCH NOTE: User {USER_ID} completed Sphere protocol but heart rate data quality is insufficient for station-level analysis. Data density {data_points_per_minute:.1f} points/minute indicates {quality_reason.lower()}. Session-level statistics preserved for general cardiovascular analysis: duration {session_duration_min:.1f} min, avg HR {final_session_avg_hr:.1f} bpm, max HR {final_session_max_hr} bpm. Recommend exclusion from station-level analyses but suitable for session-level cardiovascular trends.'\n",
        "    else:\n",
        "        # Survey and other fields marked as TBD\n",
        "        session_row[field] = 'TBD'\n",
        "\n",
        "# Write CSV file\n",
        "os.makedirs('output/processed', exist_ok=True)\n",
        "\n",
        "with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    writer.writerow(session_row)\n",
        "\n",
        "print(f\"\\n‚úÖ SUCCESS: Low-quality data exported to {OUTPUT_CSV}\")\n",
        "print(f\"üìä Created session-level record for User {USER_ID}\")\n",
        "print(f\"üìã Data quality: {quality_level}\")\n",
        "print(f\"üíæ Format compatible with high-quality user CSVs\")\n",
        "\n",
        "# Display summary\n",
        "print(f\"\\nüìä EXPORT SUMMARY:\")\n",
        "print(f\"   User ID: {USER_ID}\")\n",
        "print(f\"   Session Duration: {session_duration_min:.2f} minutes\")\n",
        "print(f\"   Data Points: {len(df)} ({data_points_per_minute:.1f}/min)\")\n",
        "print(f\"   HR Range: {session_min_hr}-{final_session_max_hr} bpm (avg: {final_session_avg_hr:.1f})\")\n",
        "print(f\"   Quality Level: {quality_level}\")\n",
        "print(f\"   Station Analysis: Not performed (data quality insufficient)\")\n",
        "\n",
        "# Show preview of exported data\n",
        "try:\n",
        "    df_export = pd.read_csv(OUTPUT_CSV)\n",
        "    print(f\"\\nüìã Exported Data Preview:\")\n",
        "    key_cols = ['user_id', 'session_duration_min', 'session_avg_hr', 'session_max_hr', 'data_quality']\n",
        "    available_cols = [col for col in key_cols if col in df_export.columns]\n",
        "    display(df_export[available_cols])\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error reading exported file for preview: {e}\")\n",
        "\n",
        "print(f\"\\nüéØ Low-quality data processing complete!\")\n",
        "print(f\"üìÑ CSV ready for master database compilation\")\n",
        "print(f\"üî¨ Data preserved for research transparency\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
