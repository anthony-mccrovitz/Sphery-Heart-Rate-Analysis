{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Heart Rate Data Analysis - Low Quality Data Template\n",
        "\n",
        "This template is designed for users with poor heart rate data quality due to sensor connection issues.\n",
        "It creates the same CSV format as other users while documenting data quality problems.\n",
        "\n",
        "## How to use this template:\n",
        "1. Change the USER_ID in cell 1\n",
        "2. Update the session date in cell 6 if needed\n",
        "3. Run all cells to generate the CSV output\n",
        "4. The CSV will have 3 station rows with proper data quality documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 1: Setup and imports\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# CONFIGURATION - Change these values for each user\n",
        "USER_ID = 0  # ‚ö†Ô∏è CHANGE THIS FOR EACH USER\n",
        "TCX_FILE = f'data/{USER_ID}-d.tcx'\n",
        "CHART_IMAGE = f'charts_cropped/user_{USER_ID}.png'\n",
        "OUTPUT_CSV = f'output/processed/user_{USER_ID}_station_data.csv'\n",
        "\n",
        "# Set working directory\n",
        "os.chdir('/Users/anthonymccrovitz/Desktop/Sphery/Sphere Heart Rate Analysis')\n",
        "\n",
        "# Add scripts directory to path\n",
        "sys.path.append('scripts')\n",
        "from parse_tcx import parse_tcx_to_df\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    df, session_total_sec, sessions_avg_hr, session_max_hr, calories_burned = parse_tcx_to_df(TCX_FILE)\n",
        "    session_duration_min = session_total_sec / 60\n",
        "    print(f\"Data loaded successfully: {len(df)} data points over {session_duration_min:.2f} minutes\")\n",
        "    print(f\"Average HR: {sessions_avg_hr:.1f} bpm, Maximum HR: {session_max_hr} bpm, Calories: {calories_burned}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    \n",
        "# Load background image\n",
        "try:\n",
        "    img = mpimg.imread(CHART_IMAGE)\n",
        "    print(f\"Background image loaded successfully from {CHART_IMAGE}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading background image: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load user metadata\n",
        "import pandas as pd\n",
        "try:\n",
        "    metadata_df = pd.read_csv('metadata/user_metadata.csv')\n",
        "    user_meta = metadata_df[metadata_df['user_id'] == USER_ID]\n",
        "    if not user_meta.empty:\n",
        "        user_meta = user_meta.iloc[0]\n",
        "        age = user_meta['age'] if not pd.isna(user_meta['age']) else None\n",
        "        gender = user_meta['gender'] if not pd.isna(user_meta['gender']) else None\n",
        "        height_cm = user_meta['height_cm'] if not pd.isna(user_meta['height_cm']) else None\n",
        "        weight_kg = user_meta['weight_kg'] if not pd.isna(user_meta['weight_kg']) else None\n",
        "        champ_number = user_meta['champ_number'] if not pd.isna(user_meta['champ_number']) else None\n",
        "        print(f\"Loaded metadata for user {USER_ID}: age={age}, gender={gender}, height={height_cm}cm, weight={weight_kg}kg, champ={champ_number}\")\n",
        "    else:\n",
        "        print(f\"No metadata found for user {USER_ID}\")\n",
        "        age = gender = height_cm = weight_kg = champ_number = None\n",
        "except Exception as e:\n",
        "    print(f\"Error loading metadata: {e}\")\n",
        "    age = gender = height_cm = weight_kg = champ_number = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directories for plots\n",
        "import os\n",
        "plots_dir = f'output/plots/user_{USER_ID}'\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "print(f\"Created plots directory: {plots_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 2: Visualize heart rate data\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(df['elapsed_min'], df['heart_rate'], linewidth=2)\n",
        "plt.xlabel('Elapsed Minutes', fontsize=12)\n",
        "plt.ylabel('Heart Rate (BPM)', fontsize=12)\n",
        "plt.title(f'Heart Rate Over Time: User {USER_ID}', fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "# Save the plot\n",
        "plt.savefig(f'{plots_dir}/heart_rate_over_time.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Show max heart rate point\n",
        "max_hr_row = df[df['heart_rate'] == df['heart_rate'].max()]\n",
        "print(\"Maximum Heart Rate Details:\")\n",
        "print(max_hr_row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 3: DATA QUALITY ASSESSMENT\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER {USER_ID} DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nüö® LOW QUALITY DATA DETECTED üö®\")\n",
        "print(\"\\nReason: Heart rate data quality is insufficient for reliable analysis.\")\n",
        "print(\"The HR data shows irregular recording patterns, likely due to:\")\n",
        "print(\"- Weak or lost connection with the Garmin HR sensor\")\n",
        "print(\"- Missing or distorted peaks\")\n",
        "print(\"- Activity zones that are not clearly distinguishable\")\n",
        "\n",
        "print(f\"\\nData Summary:\")\n",
        "print(f\"- Total data points: {len(df)}\")\n",
        "print(f\"- Session duration: {session_duration_min:.2f} minutes\")\n",
        "print(f\"- Average HR: {sessions_avg_hr:.1f} bpm\")\n",
        "print(f\"- Maximum HR: {session_max_hr} bpm\")\n",
        "print(f\"- Data points per minute: {len(df) / session_duration_min:.1f}\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  ANALYSIS:\")\n",
        "print(f\"With only {len(df)} data points over {session_duration_min:.2f} minutes,\")\n",
        "print(f\"this represents {len(df) / session_duration_min:.1f} data points per minute.\")\n",
        "print(f\"Normal HR recording should have ~12-60 data points per minute.\")\n",
        "print(f\"This sparse data indicates significant sensor connection issues.\")\n",
        "\n",
        "print(\"\\nüìä APPROACH:\")\n",
        "print(\"Creating CSV with same format as other users but marking data quality issues.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 4: STATION CUTOFFS FOR LOW-QUALITY DATA (SAME CSV FORMAT)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"STATION PROCESSING - LOW QUALITY DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nüìã CREATING SAME CSV FORMAT AS OTHER USERS\")\n",
        "print(\"\\nApproach for low-quality data:\")\n",
        "print(\"‚úÖ Create 3 station rows (same as other users)\")\n",
        "print(\"‚úÖ Use estimated time boundaries\")\n",
        "print(\"‚úÖ Mark data quality issues in notes/data_quality fields\")\n",
        "print(\"‚úÖ Keep all survey fields ready for data entry\")\n",
        "\n",
        "# Define estimated station cutoffs \n",
        "# Using typical session structure even though data is sparse\n",
        "cutoffs = [\n",
        "    (0, 14),    # Station 1 - estimated\n",
        "    (15, 28),   # Station 2 - estimated  \n",
        "    (29, 42)    # Station 3 - estimated\n",
        "]\n",
        "\n",
        "print(f\"\\nüìÖ ESTIMATED STATION BOUNDARIES:\")\n",
        "for i, (start, end) in enumerate(cutoffs, 1):\n",
        "    print(f\"Station {i}: {start:.1f} - {end:.1f} minutes\")\n",
        "\n",
        "# Notes and data quality - UPDATE THESE FOR EACH USER\n",
        "notes = f\"\"\"User {USER_ID}'s heart rate data was explored but not aligned or split into stations. The session shows irregular HR recording, likely due to a weak or lost connection with the Garmin HR sensor. Peaks are missing or distorted, and activity zones are not clearly distinguishable.\"\"\"\n",
        "\n",
        "data_quality = \"\"\"Incomplete heart rate data with long flat sections and dropouts. Unable to detect 6 gameplay peaks or station transitions. Data is unreliable for station-level or gameplay-level analysis. Marked as a low-quality session due to poor HR sensor connection.\"\"\"\n",
        "\n",
        "print(f\"\\nüìä RESULT:\")\n",
        "print(\"CSV will have 3 rows (same format as other users)\")\n",
        "print(\"Survey fields ready for data collection\")\n",
        "print(\"Data quality issues properly documented\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 5: CREATE CSV OUTPUT (SAME FORMAT AS HIGH-QUALITY USERS)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CSV OUTPUT GENERATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get session timing info from TCX data\n",
        "session_start_time = df['timestamp'].iloc[0] if len(df) > 0 else None\n",
        "session_end_time = df['timestamp'].iloc[-1] if len(df) > 0 else None\n",
        "\n",
        "print(f\"üìÖ SESSION TIMING:\")\n",
        "print(f\"Session start: {session_start_time}\")\n",
        "print(f\"Session end: {session_end_time}\")\n",
        "print(f\"Session duration: {session_duration_min:.2f} minutes\")\n",
        "\n",
        "# Create CSV with same format as high-quality users (3 station rows)\n",
        "csv_rows = []\n",
        "\n",
        "for i, (start_min, end_min) in enumerate(cutoffs, 1):\n",
        "    # Calculate basic stats for this time period (even with sparse data)\n",
        "    station_data = df[(df['elapsed_min'] >= start_min) & (df['elapsed_min'] <= end_min)]\n",
        "    \n",
        "    if len(station_data) > 0:\n",
        "        station_avg_hr = round(station_data['heart_rate'].mean(), 1)\n",
        "        station_max_hr = int(station_data['heart_rate'].max())\n",
        "        # Calculate station start/end timestamps\n",
        "        station_start_time = station_data['timestamp'].iloc[0]\n",
        "        station_end_time = station_data['timestamp'].iloc[-1]\n",
        "    else:\n",
        "        # No data points in this time range - estimate timestamps\n",
        "        station_avg_hr = None\n",
        "        station_max_hr = None\n",
        "        # Estimate timestamps based on session start + elapsed minutes\n",
        "        if session_start_time:\n",
        "            import pandas as pd\n",
        "            station_start_time = session_start_time + pd.Timedelta(minutes=start_min)\n",
        "            station_end_time = session_start_time + pd.Timedelta(minutes=end_min)\n",
        "        else:\n",
        "            station_start_time = None\n",
        "            station_end_time = None\n",
        "    \n",
        "    # Match high-quality users' column structure EXACTLY (same order and column names)\n",
        "    row = {\n",
        "        'user_id': USER_ID,\n",
        "        'gender': gender if gender and str(gender).strip() else ' ',  # Use space like User 2\n",
        "        'circuit_type': 'NA',  # Use 'NA' like User 2, you can update this\n",
        "        'age': age if age is not None else '',  # Empty string if None\n",
        "        'height_cm': height_cm if height_cm is not None else '',\n",
        "        'weight_kg': weight_kg if weight_kg is not None else '',\n",
        "        'champ_number': champ_number,\n",
        "        'calories_burned': calories_burned,\n",
        "        'station_number': i,\n",
        "        'station_name': 'NA',  # Use 'NA' like User 2, you can update this\n",
        "        'session_start_time': session_start_time,\n",
        "        'session_end_time': session_end_time,\n",
        "        'session_duration_min': session_duration_min,\n",
        "        'session_avg_hr': sessions_avg_hr,\n",
        "        'session_max_hr': session_max_hr,\n",
        "        'station_start_time': station_start_time,\n",
        "        'station_end_time': station_end_time,\n",
        "        'station_duration_min': end_min - start_min,\n",
        "        'station_avg_hr': station_avg_hr,\n",
        "        'station_max_hr': station_max_hr,\n",
        "        # Survey fields - use 'NA' like User 2 (ready for your data entry)\n",
        "        'motivation': 'NA',\n",
        "        'enjoyment': 'NA',\n",
        "        'team_experience': 'NA',\n",
        "        'subjective_physical_exertion': 'NA',\n",
        "        'subjective_cognitive_exertion': 'NA',\n",
        "        'overall_experience': 'NA',\n",
        "        'overall_motivation': 'NA',\n",
        "        'feedback': 'NA',\n",
        "        'sports_exp': 'NA',\n",
        "        'gaming_exp': 'NA',\n",
        "        'data_quality': data_quality,\n",
        "        'notes': notes\n",
        "    }\n",
        "    csv_rows.append(row)\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "df_output = pd.DataFrame(csv_rows)\n",
        "df_output.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "print(f\"‚úÖ CSV file saved to: {OUTPUT_CSV}\")\n",
        "print(f\"üìä Record count: {len(df_output)} (3 stations)\")\n",
        "print(\"\\nüìã CSV Structure (matches high-quality users):\")\n",
        "print(f\"- User ID: {USER_ID}\")\n",
        "print(f\"- Stations: 3 rows\")\n",
        "print(f\"- Session timestamps: ‚úÖ Collected from TCX\")\n",
        "print(f\"- Station timestamps: ‚úÖ Collected/estimated\")\n",
        "print(f\"- Survey fields: Ready for data entry\")\n",
        "print(f\"- Data quality: Documented\")\n",
        "\n",
        "print(\"\\nüìä RECORD PREVIEW:\")\n",
        "print(df_output[['user_id', 'station_number', 'session_start_time', 'station_start_time', 'station_duration_min', 'station_avg_hr']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 6: FINAL SUMMARY\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"ANALYSIS COMPLETE - USER {USER_ID}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n‚úÖ Heart rate data processed for User {USER_ID}\")\n",
        "print(f\"‚úÖ CSV created with same format as other users\")\n",
        "print(f\"‚úÖ Output saved to: {OUTPUT_CSV}\")\n",
        "print(\"‚ö†Ô∏è  Note: Data quality issues documented in CSV\")\n",
        "\n",
        "print(f\"\\nüìä DATA SUMMARY:\")\n",
        "print(f\"User ID: {USER_ID}\")\n",
        "print(f\"Data Points: {len(df)}\")\n",
        "print(f\"Session Duration: {session_duration_min:.2f} minutes\")\n",
        "print(f\"Data Density: {len(df) / session_duration_min:.1f} points/minute\")\n",
        "print(f\"Average HR: {sessions_avg_hr:.1f} bpm\")\n",
        "print(f\"Maximum HR: {session_max_hr} bpm\")\n",
        "\n",
        "print(f\"\\nüíæ OUTPUT:\")\n",
        "print(f\"‚úÖ CSV file: {OUTPUT_CSV}\")\n",
        "print(f\"‚úÖ Format: 3 station rows (same as other users)\")\n",
        "print(f\"‚úÖ Survey fields: Ready for data entry\")\n",
        "print(f\"‚úÖ Data quality: Documented for research\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
